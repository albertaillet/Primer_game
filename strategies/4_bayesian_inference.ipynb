{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from game_simulation import CoinGameSimulation\n",
    "from game_browser import CoinGameBrowser\n",
    "from simulate_strategy import simulate_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pgm():\n",
    "    y = 1 \n",
    "    pgm = daft.PGM()\n",
    "    pgm.add_node(\"p\", r\"$p$\", 0, y, fixed=True, offset=(1, 3))\n",
    "    pgm.add_node(\"L\", r\"$L$\", 1, y)\n",
    "    pgm.add_node(\"theta\", r\"$\\theta$\", 2, y)\n",
    "    pgm.add_node(\"H_n\", r\"$H_n$\", 3, y, observed=True)\n",
    "    pgm.add_edge(\"p\", \"L\")\n",
    "    pgm.add_edge(\"L\", \"theta\")\n",
    "    pgm.add_edge(\"theta\", \"H_n\")\n",
    "    pgm.add_plate([2.5, 0.5, 1, 1], label=r\"$n = 1:N$\", shift=-0.2)\n",
    "    return pgm.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategy: make use of Bayesian inference.\n",
    "This strategy uses Bayesian inference to determine the best strategy to play if we do not know either to probability of what kind of oppenent we get and if we do not know with the probability of the skwed coin.\n",
    "\n",
    "The following wikipedia pages were used as reference \n",
    "[Checking whether a coin is fair](https://en.wikipedia.org/wiki/Checking_whether_a_coin_is_fair) and [Bayesian inference](https://en.wikipedia.org/wiki/Bayesian_inference).\n",
    "\n",
    "The following code shows the probabilitic graphical model for the coin flip distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pgm().set_title(\"PGM of Coin flip\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- $p$: The probability of the opponent being fair.\n",
    "- $L$:  Bernouilli distribution with unkown parameter p. Determines if the opponent is a cheater or not.\n",
    "- $\\theta$: Unkown distribution with values $\\in [0, 1]$. Gives parameters of the Bernoulli distribution of H.\n",
    "- $H_{1:N}$: Bernouilli distribution with parameter $\\theta$ and $N$ samples. Gives the number of heads.\n",
    "\n",
    "We use Bayes rule to get:\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(L | H_{1:N}) &= \\frac{P(H_{1:N} | L) \\cdot P(L)}{P(H_{1:N})} \\\\\n",
    "               &= \\frac{\\sum_{\\theta=0}^1 P(H_{1:N}, \\theta | L) \\cdot P(L)}{P(H_{1:N})} \\\\\n",
    "               &= \\frac{\\sum_{\\theta=0}^1 P(H_{1:N} | \\theta, L) \\cdot P(\\theta | L) \\cdot P(L)}{P(H_{1:N})} \\\\\n",
    "               &= \\frac{\\sum_{\\theta=0}^1 P(H_{1:N} | \\theta) \\cdot P(\\theta | L) \\cdot P(L)}{P(H_{1:N})} \\\\\n",
    "               &\\propto \\sum_{\\theta=0}^1 P(H_{1:N} | \\theta) \\cdot P(\\theta | L) \\cdot P(L) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "After choosing the label, we get to know the true Label L.\n",
    "We can then update the priors $P(\\theta | L)$ and $P(L)$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(L | H_{1:N}) &= \\frac{P(H_{1:N} | L) \\cdot P(H_{})}{P(H_{1:N} | L)} \\\\\n",
    "&= \\frac{P(H_{1:N} | \\theta) \\cdot P(\\theta | L)}{P(H_{1:N} | L)} \\\\\n",
    "&\\propto P(H_{1:N} | \\theta) \\cdot P(\\theta | L)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "P(\\theta | L, H_{1:N}) &= \\frac{P(H_{1:N} | \\theta, L) \\cdot P(\\theta | L)}{P(H_{1:N} | L)} \\\\\n",
    "&= \\frac{P(H_{1:N} | \\theta) \\cdot P(\\theta | L)}{P(H_{1:N} | L)} \\\\\n",
    "&\\propto P(H_{1:N} | \\theta) \\cdot P(\\theta | L)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyBayseianInference:\n",
    "\n",
    "    def __init__(self, \n",
    "                 n = 101, \n",
    "                 threshold = 0.75, \n",
    "                 flip_5_at_start = False):\n",
    "        assert 0 <= threshold <= 1\n",
    "        # n is the number of theta values.\n",
    "        # the threshold is the theshold to use when deciding the label.\n",
    "        self.threshold = threshold \n",
    "        self.theta = np.linspace(0, 1, n)\n",
    "        self.theta_L = np.zeros((n, 2))\n",
    "        self.theta_L[self.theta > 0.5, 1] = 1\n",
    "        self.theta_L[(0.45 < self.theta)&(self.theta < 0.55), 0] = 1\n",
    "        self.theta_L /= self.theta_L.sum(axis=0)\n",
    "        \n",
    "        # probability of label 0: fair\n",
    "        self.observed_L = [0, 1]\n",
    "        self.p = np.mean(self.observed_L)\n",
    "\n",
    "        self.last_flips_left = 0\n",
    "        self.last_n_heads = 0\n",
    "        self.last_n_tails = 0\n",
    "        self.last_action = 0\n",
    "        self.last_label = None\n",
    "        self.flip_5_at_start = flip_5_at_start\n",
    "\n",
    "    def set_theshold(self, threshold):\n",
    "        assert 0 <= threshold <= 1\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def update(self, reward=None, flips_left=None):  \n",
    "        if self.last_label is None:\n",
    "            return\n",
    "        if reward is not None:\n",
    "            self.get_correct_label(reward)\n",
    "        elif flips_left is not None:\n",
    "            flips_left_diff = flips_left - self.last_flips_left\n",
    "            self.get_correct_label(flips_left_diff)\n",
    "        else:\n",
    "            raise ValueError(\"Either reward or flips_left must be given.\")\n",
    "        \n",
    "        self.last_label = None\n",
    "        c_label = self.last_correct_label\n",
    "\n",
    "        # estimate p once again\n",
    "        self.observed_L.append(c_label)\n",
    "        self.p = np.mean(self.observed_L)\n",
    "\n",
    "        # update theta_L using bayesian inference\n",
    "        self.theta_L[:, c_label] = self.probability_of_observation * self.theta_L[:, c_label]\n",
    "        self.theta_L /= self.theta_L.sum(axis=0)\n",
    "    \n",
    "    def get_correct_label(self, reward):\n",
    "        if reward == 15:\n",
    "            correct_label = True\n",
    "        elif reward == -30:\n",
    "            correct_label = False\n",
    "        else:\n",
    "            raise ValueError(f\"Reward ({reward} is not 15 or -30.\")\n",
    "        \n",
    "        if correct_label:\n",
    "            self.last_correct_label = self.last_label\n",
    "        else:\n",
    "            self.last_correct_label = (self.last_label + 1) % 2\n",
    "\n",
    "\n",
    "    def strategy(self, n_heads, n_tails, flips_left):\n",
    "        self.last_flips_left = flips_left\n",
    "\n",
    "        if self.flip_5_at_start and n_heads + n_tails == 0 and flips_left >= 5:\n",
    "            return 1\n",
    "        \n",
    "        theta = self.theta\n",
    "        self.probability_of_observation = theta ** n_heads * (1 - theta) ** n_tails\n",
    "\n",
    "        posterior = self.probability_of_observation.dot(self.theta_L) * np.array([self.p, 1 - self.p])\n",
    "        posterior /= np.sum(posterior)\n",
    "\n",
    "        \n",
    "\n",
    "        if np.max(posterior) > self.threshold or flips_left == 0:\n",
    "            label = np.argmax(posterior)\n",
    "            self.last_label = label\n",
    "            return label + 2\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = StrategyBayseianInference(n=101)\n",
    "g = CoinGameSimulation()\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    (n_heads, n_tails, flips_left) = g.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = strat.strategy(n_heads, n_tails, flips_left)\n",
    "        (n_heads, n_tails, flips_left), reward, done, info = g.step(action)\n",
    "        #strat.update(reward=reward)\n",
    "\n",
    "    score = info[\"score\"]\n",
    "    scores.append(score)\n",
    "    if score >= 100:\n",
    "        clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(20, 4))\n",
    "        ax[0].plot(strat.probability_of_observation)\n",
    "        ax[0]\n",
    "        ax[1].plot(strat.theta_L[:, 0], label=\"L=0\")\n",
    "        ax[2].plot(strat.theta_L[:, 1], label=\"L=1\")\n",
    "        ax[3].plot(scores, label=\"scores\")\n",
    "        fig.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat.set_theshold(0.70)\n",
    "simulate_strategy(strat.strategy, n_simulations=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strat.flip_5_at_start = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = CoinGameBrowser()\n",
    "log_file = \"logs/log_strat_4_5_start.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(log_file, 'w') as f:\n",
    "    f.write('Score,Flips left,Heads,Tails,Action,Reward\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    (n_heads, n_tails, flips_left) = g.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = strat.strategy(n_heads, n_tails, flips_left)\n",
    "        (n_heads, n_tails, flips_left), reward, done, info = g.step(action)\n",
    "        score = info[\"score\"]\n",
    "        with open(log_file, 'a') as f:\n",
    "            f.write(f'{score:3},{flips_left:3},{n_heads:2},{n_tails:2},{action:2},{reward:3}\\n')\n",
    "    if score > 100:\n",
    "        break\n",
    "\n",
    "from pygame import mixer, time\n",
    "mixer.init()\n",
    "while True:\n",
    "    sound = mixer.Sound(\"coin-win-notification.wav\")\n",
    "    sound.play()\n",
    "    time.wait(int(sound.get_length() * 1000))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fc32a243a6b87027c9f6195a114662f388139f44cd834ded9ed282018985cc20"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('web-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
